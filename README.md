# Federated Learning - Flower Project

Este Ã© um projeto simples de **Aprendizado Federado (FL)** usando o framework **Flower**, desenvolvido como parte do Trabalho de ConclusÃ£o de Curso (TCC) para a EspecializaÃ§Ã£o em SeguranÃ§a CibernÃ©tica da Universidade Federal de UberlÃ¢ndia (UFU).  
O objetivo Ã© treinar um modelo de classificaÃ§Ã£o a partir do dataset `ERENO-2.0-100K.csv` e medir o **impacto da tÃ©cnica de envenenamento de rÃ³tulos (Label Poisoning)** na degradaÃ§Ã£o do desempenho do modelo.

Download do dataset [Aqui](https://drive.google.com/file/d/1Il9YL3cOv8ret1NPoDVITSEbwRyaNoRV/view?usp=drivesdk).

---

## ğŸ“‚ Estrutura
```
UFU_TCC_FED_LEARNING/
â”‚
â”œâ”€ data/
â”‚   â”œâ”€ ERENO-2.0-100K.csv          # Dataset original
â”‚   â””â”€ ERENO-2.0-100K-poisoned.csv # Dataset envenenado (gerado pelo poison.py)
â”‚
â”œâ”€ src/
â”‚   â”œâ”€ client.py                   # Cliente FL
â”‚   â”œâ”€ server.py                   # Servidor FL
â”‚   â”œâ”€ model.py                    # DefiniÃ§Ã£o do modelo
â”‚   â”œâ”€ dataset.py                  # Dataset e prÃ©-processamento
â”‚   â”œâ”€ poison.py                   # MÃ³dulo de envenenamento
â”‚   â””â”€ analyze.py                  # AnÃ¡lise automÃ¡tica (com mÃ©tricas + grÃ¡ficos)
â”‚
â”œâ”€ requirements.txt                # Dependencias libs/modulos
â””â”€ README.md                       # InstruÃ§Ãµes/documentaÃ§Ã£o
```



Este Ã© um projeto simples de **aprendizado federado** usando o framework **Flower** e um dataset em CSV.



## Requisitos:
```
flwr
scikit-learn
pandas
numpy
matplotlib
```

## Arquivos
- `data/ERENO-2.0-100K.csv` â†’ Dataset original
- `ERENO-2.0-100K-poisoned.csv` â†’ Dataset envenenado
- `src/client.py` â†’ Cliente FL
- `src/server.py` â†’ Servidor FL
- `src/model.py` â†’ DefiniÃ§Ã£o do modelo
- `src/dataset.py` â†’ PrÃ©-processamento
- `src/poison.py` â†’ SimulaÃ§Ã£o de **Label Poisoning**
- `src/analyze.py` â†’ AnÃ¡lise automÃ¡tica


## âš™ï¸ InstalaÃ§Ã£o

1. Clone este repositÃ³rio ou copie os arquivos.
2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## ğŸš€ Como Rodar
1. Rodar servidor e clientes manualmente (modo federado tradicional)

Inicie o servidor:
```bash
python src/server.py
```

Em dois terminais separados, inicie os clientes:
```bash
python src/client.py
python src/client.py
```

2. Gerar dataset envenenado

Para criar uma versÃ£o com label poisoning:
```bash
python src/poison.py
```
* **Isso vai gerar data/ERENO-2.0-100K-poisoned.csv, que pode ser usado no lugar do dataset original para ver o impacto na acurÃ¡cia e precisÃ£o**

3. Executar anÃ¡lise comparativa automÃ¡tica com mÃ©tricas e grÃ¡ficos

Execute:
```bash
python src/analyze.py
```

**Isso roda o aprendizado federado duas vezes:**

* 1x com dataset limpo

* 1x com dataset envenenado

**E gera:**

* **Arquivos JSON**

* * results_clean.json â†’ mÃ©tricas finais do dataset limpo

* * results_poison.json â†’ mÃ©tricas finais do dataset envenenado

* **GrÃ¡ficos comparativos**

* * comparison_accuracy.png

* * comparison_precision.png

* * comparison_recall.png

* * comparison_f1.png


## ğŸ“Š InterpretaÃ§Ã£o dos Resultados

**JSONs (`results_clean.json`, `results_poison.json`)**

**Exemplo de saÃ­da em `results_clean.json`:**

```bash
{
    "dataset": "data/ERENO-2.0-100K.csv",
    "final_accuracy": 0.9123,
    "final_precision": 0.9101,
    "final_recall": 0.9110,
    "final_f1": 0.9105
}
```

* **final_accuracy** â†’ porcentagem de acertos do modelo.

* **final_precision** â†’ capacidade de evitar falsos positivos.

* **final_recall** â†’ capacidade de identificar corretamente os positivos.

* **final_f1** â†’ equilÃ­brio entre precisÃ£o e recall.

## ğŸ“Œ Compare com o `results_poison.json`.
A diferenÃ§a entre os dois mostra a degradaÃ§Ã£o causada pelo poisoning.

## GrÃ¡ficos (comparison_*.png)

Cada grÃ¡fico mostra a evoluÃ§Ã£o de uma mÃ©trica ao longo dos rounds de FL:

* **Linha Clean** â†’ Treinamento com dataset original.

* **Linha Poisoned** â†’ Treinamento com dataset envenenado.

Se o envenenamento for eficaz, vocÃª verÃ¡:

* AcurÃ¡cia caindo.

* PrecisÃ£o e Recall distorcidos (dependendo de quais classes foram afetadas).

* F1-score reduzido (indicando perda de equilÃ­brio entre precisÃ£o e recall).

## ğŸ“Œ ConclusÃ£o

### ğŸ‘‰ Com este projeto vocÃª irÃ¡:

- Entender como funciona o aprendizado federado bÃ¡sico com Flower.
- Treinar logistic regression via **federated averaging (FedAvg)**
- Simular ataques de label poisoning.
- Medir quantitativamente o impacto depois do envenenamento usando `Accuracy`, `Precision`, `Recall` e `F1-score`. 
- Visualizar graficamente a degradaÃ§Ã£o de desempenho do modelo.
- Facilmente adaptar para novos experimentos.
